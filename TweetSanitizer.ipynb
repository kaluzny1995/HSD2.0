{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Sanitizer\n",
    "---\n",
    "A Python code to sanitize i.e. remove hashtags, mentions, links, photos, etc. from raw tweet content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import emot\n",
    "import emoji\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_polish(in_file, out_file):\n",
    "    with open(in_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        \n",
    "        with open(out_file, 'w') as wf:\n",
    "            writer = csv.writer(wf)\n",
    "            writer.writerow(header)\n",
    "            \n",
    "            for row in reader:\n",
    "                if row[11] == 'pl':\n",
    "                    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "reduce_to_polish('data/sady_supplement/sady_2017_0105_raw.csv',\n",
    "                 'data/sady_supplement/sady_2017_0105_raw_pl.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARTIAL SANITIZATION**\n",
    "\n",
    "Remove:\n",
    "* strange non-utf-8 characters\n",
    "* user mentions\n",
    "* links {https://t.co/P3zt8zBUbL}\n",
    "* photos content {pic.twitter.com...}\n",
    "* hashtags with hashcodes {#.43djr324rj34}\n",
    "* special characters {/w; /n; /r}\n",
    "* redundant spaces\n",
    "\n",
    "\n",
    "**FULL SANITIZATION**\n",
    "\n",
    "Remove:\n",
    "* all like in partial sanitization\n",
    "* all hashtag hashes {#}\n",
    "* others but texts\n",
    "\n",
    "Extract:\n",
    "* emoticons {:); ;)}\n",
    "* emoji {ü§¶‚Äç‚ôÇÔ∏è; ü§£; üòÇ; ü§£}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_sanitization(text):\n",
    "    url_pat = '(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+|http[s]?://)'\n",
    "    mention_pat = '@[\\w\\-]+'\n",
    "    photo_pat = 'pic.twitter.com\\/[\\w\\-]+'\n",
    "    hashcode_pat = '#.[a-zA-Z0-9]{11}.*(twitter|facebook|reddit|youtube)'\n",
    "    multidot_pat = '(\\.\\.\\.|‚Ä¶)'\n",
    "    black_sq_pat = '‚ñ†'\n",
    "    space_pat = '\\s+'\n",
    "    \n",
    "    text = re.sub(url_pat, '', text)\n",
    "    text = re.sub(mention_pat, '', text)\n",
    "    text = re.sub(photo_pat, '', text)\n",
    "    text = re.sub(hashcode_pat, '', text)\n",
    "    text = re.sub(multidot_pat, '', text)\n",
    "    text = re.sub(black_sq_pat, '', text)\n",
    "    text = re.sub(space_pat, ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_emoji_(text):\n",
    "    desc = emot.emoji(text)\n",
    "    emojis = ' '.join(desc['value'])\n",
    "    \n",
    "    for emoji_ in set(desc['value']):\n",
    "        text = re.sub(emoji_, '', text)\n",
    "    \n",
    "    return text, emojis\n",
    "\n",
    "def extract_emoji(text):\n",
    "    emoji_list = [c for c in text if c in emoji.UNICODE_EMOJI]\n",
    "    emojis = ' '.join(emoji_list)\n",
    "    \n",
    "    for emoji_ in emoji_list:\n",
    "        text = re.sub(emoji_, '', text)\n",
    "    \n",
    "    return text, emojis\n",
    "\n",
    "def extract_emoticons(text):\n",
    "    desc = emot.emoticons(text)\n",
    "    try:  # there's a bug in 'emot' library causing TypeError in some cases\n",
    "        emoticons = ' '.join(desc['value'])\n",
    "        \n",
    "        for emoticon in set([''.join(f'\\{x}' for x in v) for v in desc['value']]):\n",
    "            try:\n",
    "                text = re.sub(emoticon, '', text)\n",
    "            except Exception:\n",
    "                pass\n",
    "    except TypeError:\n",
    "        emoticons, emoticon_text, emoticon_pos = '', '', ''\n",
    "        \n",
    "    return text, emoticons\n",
    "\n",
    "def full_sanitization(text):\n",
    "    text = partial_sanitization(text)\n",
    "    \n",
    "    hash_pat = '#'\n",
    "    space_pat = '\\s+'\n",
    "    text = re.sub(hash_pat, '', text)\n",
    "    \n",
    "    text, emojis = extract_emoji(text)\n",
    "    text, emoticons = extract_emoticons(text)\n",
    "    \n",
    "    text = re.sub(space_pat, ' ', text)\n",
    "    \n",
    "    return text, emojis, emoticons\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Kompania #Wƒôglowa @weglowa :( pic.twitter.com/O2ixmQ2Jm1 https:// blokuje ≈õlƒÖskie sƒÖdy. http://niezalezna.pl/209246-sprawdzili-czy-tusk üòÇ 20 tysiƒôcy pozw√≥w ws. deputat√≥w wƒôglowych :/- Dziennik...zachodni.pl:http://niezalezna.pl/209246-sprawdzili-czy-tusk-jest-winny #.VIXGNXEL7p8.twitter ‚Ä¶'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = '#Kompania #Wƒôglowa @weglowa :( pic.twitter.com/O2ixmQ2Jm1 https:// blokuje ≈õlƒÖskie sƒÖdy. http://niezalezna.pl/209246-sprawdzili-czy-tusk üòÇ 20 tysiƒôcy pozw√≥w ws. deputat√≥w wƒôglowych :/- Dziennik...zachodni.pl:http://niezalezna.pl/209246-sprawdzili-czy-tusk-jest-winny #.VIXGNXEL7p8.twitter ‚Ä¶'\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Kompania #Wƒôglowa :( blokuje ≈õlƒÖskie sƒÖdy. üòÇ 20 tysiƒôcy pozw√≥w ws. deputat√≥w wƒôglowych :/- Dziennikzachodni.pl: '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_sanitization(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Kompania Wƒôglowa blokuje ≈õlƒÖskie sƒÖdy. 20 tysiƒôcy pozw√≥w ws. deputat√≥w wƒôglowych - Dziennikzachodni.pl: ',\n",
       " 'üòÇ',\n",
       " ':( :/')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_sanitization(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This does not work: \\U0001f928, !üáµ, \\U0001f92a, and \\U0001f97a. But this  works!',\n",
       " 'üòÇ')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_emoji_('This does not work: ü§®, !üáµ, ü§™, and ü•∫. But this üòÇ works!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This does not work: , !, , and . But this  works!',\n",
       " '\\U0001f928 üáµ \\U0001f92a \\U0001f97a üòÇ')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_emoji('This does not work: ü§®, !üáµ, ü§™, and ü•∫. But this üòÇ works!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_tweets(in_file, out_file, full_sanitize=False, reduce_to_polish=True, save_texts_only=False):\n",
    "    with open(in_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        \n",
    "        # 10-th column is a tweet to sanitize; 11-th column is tweet language\n",
    "        with open(out_file, 'w') as wf:\n",
    "            writer = csv.writer(wf)\n",
    "            if save_texts_only:\n",
    "                writer.writerow(['tweet'])\n",
    "            else:\n",
    "                if full_sanitize:\n",
    "                    writer.writerow(header[:11] + ['emojis', 'emoticons'] + header[11:])\n",
    "                else:\n",
    "                    writer.writerow(header)\n",
    "\n",
    "            for row in reader:\n",
    "                if not reduce_to_polish or row[11] == 'pl':\n",
    "                    if save_texts_only:\n",
    "                        if full_sanitize:\n",
    "                            text, _, _ = full_sanitization(row[10])\n",
    "                            writer.writerow([text])\n",
    "                        else:\n",
    "                            text = partial_sanitization(row[10])\n",
    "                            writer.writerow([text])\n",
    "                    else:\n",
    "                        if full_sanitize:\n",
    "                            text, emojis, emoticons = full_sanitization(row[10])\n",
    "                            writer.writerow(row[:10] + [text, emojis, emoticons] + row[11:])\n",
    "                        else:\n",
    "                            text = partial_sanitization(row[10])\n",
    "                            writer.writerow(row[:10] + [text] + row[11:])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sanitize_tweets('data/sady_supplement/sady_2017_0105_raw.csv',\n",
    "                'data/sady_supplement/sady_2017_0105_part_sanitized.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sanitize_tweets('data/sady_supplement/sady_2017_0105_raw.csv',\n",
    "                'data/sady_supplement/sady_2017_0105_sanitized.csv', full_sanitize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitize_tweets('data/sady_supplement/sady_infos_raw.csv', 'data/sady_supplement/sady_infos_sanitized.csv',\n",
    "                full_sanitize=True, reduce_to_polish=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all texts from vulgar tweets.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for file in tqdm(os.listdir('data/vulgars_net')):\n",
    "    sanitize_tweets(f'data/vulgars_net/{file}',\n",
    "                    f'data/vulgars__texts/{file.replace(\".csv\", \"__texts.csv\")}',\n",
    "                    full_sanitize=True, save_texts_only=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for file in tqdm(os.listdir('data/vulgars_additionalwn')):\n",
    "    sanitize_tweets(f'data/vulgars_additionalwn/{file}',\n",
    "                    f'data/vulgars__texts/{file.replace(\".csv\", \"__texts.csv\")}',\n",
    "                    full_sanitize=True, save_texts_only=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
