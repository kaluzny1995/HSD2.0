{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech Detector 2.0\n",
    "---\n",
    "**Initial data analysis**\n",
    "1. Selection of relevant tweet data.\n",
    "    1. {'new_id', 'date', 'time', 'user_id', 'username', 'name', 'tweet', 'emojis', 'emoticons', 'mentions'}\n",
    "    2. {'hashtags', 'reply_to', 'replies_count', 'retweets_count', 'likes_count'}\n",
    "2. Combining selected data with their annotations and saving into separete files.\n",
    "3. Cardinalities and combination od classes counting + visualization.\n",
    "4. Hateful phrases analysis:\n",
    "    1. Set of raw hateful phrases\n",
    "    2. Set of lemmatized hateful phrases\n",
    "    3. Set of synonymic hateful phrases\n",
    "    4. Calculation of phrases appearance is text \n",
    "        1. Does appear fully or partially, how?\n",
    "        2. Get max and mean values.\n",
    "        3. 1.0 means hate speech --> 0.0 mean no hate speech\n",
    "5. For each of 7 hate speech classes:\n",
    "    1. Load appropriate .txt file with hateful lemmatized phrases.\n",
    "    2. Load appropriate .txt file with synonymic hateful phrases.\n",
    "    3. For each lemmatized tweet:\n",
    "        1. Calculate min, mean and max PAC (Phrase Appearance Coefficient) scores.\n",
    "        2. Get means of mins, means and maxes.\n",
    "6. Polish polyglot sentiment analysis\n",
    "7. Characters, syllables, words counting.\n",
    "8. For each tweet:\n",
    "    1. Determine how many words have which type of sentiment.\n",
    "    2. Count characters, syllables, words and unique words.\n",
    "9. For each of 7 hate speech classes and one vulgar:\n",
    "    1. Detect 10 hateful topics which include 10 words.\n",
    "    2. Save LDA model.\n",
    "    3. For each tweet:\n",
    "        1. Calculate PAC scores of topics appearance and mean aggregate over topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "\n",
    "import morfeusz2\n",
    "from pyplwnxml import PlwnxmlParser\n",
    "\n",
    "from polyglot.text import Text\n",
    "from polyglot.downloader import downloader\n",
    "\n",
    "import pyphen\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyglot.detect.base import logger as polyglot_logger\n",
    "polyglot_logger.setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polish stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'aby', 'ach', 'acz', 'aczkolwiek', 'aj', 'albo', 'ale', 'alez', 'ależ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/other/polish_stopwords.txt', 'r') as f:\n",
    "    polish_stopwords = f.read().split('\\n')[:-1]\n",
    "polish_stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/Dokumenty/venv36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>new_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4,74999593189773E+017</td>\n",
       "      <td>4,74982910425301E+017</td>\n",
       "      <td>1402083702000</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>21:41:42</td>\n",
       "      <td>CEST</td>\n",
       "      <td>2367137142</td>\n",
       "      <td>krzysztofcicho3</td>\n",
       "      <td>Krzysztof Cichosz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '2367137142', 'username': 'KrzysztofCicho3'}, {'user_id': '244246777', 'username': 'TomSokolewicz'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4,74958618094105E+017</td>\n",
       "      <td>4,74958618094105E+017</td>\n",
       "      <td>1402073933000</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>18:58:53</td>\n",
       "      <td>CEST</td>\n",
       "      <td>780543464</td>\n",
       "      <td>zalewski53</td>\n",
       "      <td>Roland Zalewski</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '780543464', 'username': 'Zalewski53'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id        conversation_id     created_at        date  \\\n",
       "0  4,74999593189773E+017  4,74982910425301E+017  1402083702000  2014-06-06   \n",
       "1  4,74958618094105E+017  4,74958618094105E+017  1402073933000  2014-06-06   \n",
       "\n",
       "       time timezone     user_id         username               name place  \\\n",
       "0  21:41:42     CEST  2367137142  krzysztofcicho3  Krzysztof Cichosz   NaN   \n",
       "1  18:58:53     CEST   780543464       zalewski53    Roland Zalewski   NaN   \n",
       "\n",
       "   ... source user_rt_id user_rt retweet_id  \\\n",
       "0  ...    NaN        NaN     NaN        NaN   \n",
       "1  ...    NaN        NaN     NaN        NaN   \n",
       "\n",
       "                                                                                                            reply_to  \\\n",
       "0  [{'user_id': '2367137142', 'username': 'KrzysztofCicho3'}, {'user_id': '244246777', 'username': 'TomSokolewicz'}]   \n",
       "1                                                               [{'user_id': '780543464', 'username': 'Zalewski53'}]   \n",
       "\n",
       "  retweet_date  translate  trans_src  trans_dest new_id  \n",
       "0          NaN        NaN        NaN         NaN      0  \n",
       "1          NaN        NaN        NaN         NaN      1  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_infos = pd.read_csv('data/sady_main/sady_infos_sanitized.csv')\n",
    "df_infos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
       "       'user_id', 'username', 'name', 'place', 'tweet', 'emojis', 'emoticons',\n",
       "       'mentions', 'urls', 'photos', 'replies_count', 'retweets_count',\n",
       "       'likes_count', 'hashtags', 'cashtags', 'link', 'retweet', 'quote_url',\n",
       "       'video', 'near', 'geo', 'source', 'user_rt_id', 'user_rt', 'retweet_id',\n",
       "       'reply_to', 'retweet_date', 'translate', 'trans_src', 'trans_dest',\n",
       "       'new_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_infos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>wydźwięk</th>\n",
       "      <th>klucze</th>\n",
       "      <th>wyzywanie</th>\n",
       "      <th>grożenie</th>\n",
       "      <th>wykluczanie</th>\n",
       "      <th>odczłowieczanie</th>\n",
       "      <th>poniżanie</th>\n",
       "      <th>stygmatyzacja</th>\n",
       "      <th>szantaż</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  wydźwięk klucze  wyzywanie  grożenie  wykluczanie  odczłowieczanie  \\\n",
       "0   9         1    NaN        NaN       NaN          NaN              NaN   \n",
       "1   8         0    NaN        NaN       NaN          NaN              NaN   \n",
       "2   7         0    NaN        NaN       NaN          NaN              NaN   \n",
       "3   4         0    NaN        NaN       NaN          NaN              NaN   \n",
       "4   3        -1    NaN        NaN       NaN          NaN              NaN   \n",
       "\n",
       "   poniżanie  stygmatyzacja  szantaż  \n",
       "0        NaN            NaN      NaN  \n",
       "1        NaN            NaN      NaN  \n",
       "2        NaN            NaN      NaN  \n",
       "3        NaN            NaN      NaN  \n",
       "4        NaN            NaN      NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotated = pd.read_csv('data/sady_main/sady_date_annotated.csv', sep='\\t')\n",
    "df_annotated = df_annotated.drop(columns=['date', 'time', 'tekst', 'inne', 'inne.1'])\n",
    "df_annotated = df_annotated.drop(columns=['ksenofobia', 'szowinizm', 'rasizm', 'seksizm',\n",
    "                                          'antysemityzm', 'homofobia'])\n",
    "df_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>21:41:42</td>\n",
       "      <td>2367137142</td>\n",
       "      <td>krzysztofcicho3</td>\n",
       "      <td>Krzysztof Cichosz</td>\n",
       "      <td>Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['tomsokolewicz']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'user_id': '2367137142', 'username': 'KrzysztofCicho3'}, {'user_id': '244246777', 'username': 'TomSokolewicz'}]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>18:58:53</td>\n",
       "      <td>780543464</td>\n",
       "      <td>zalewski53</td>\n",
       "      <td>Roland Zalewski</td>\n",
       "      <td>Polska Polityka: Sądy bardziej bezkarne niż w PRL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'user_id': '780543464', 'username': 'Zalewski53'}]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_id        date      time     user_id         username  \\\n",
       "0       0  2014-06-06  21:41:42  2367137142  krzysztofcicho3   \n",
       "1       1  2014-06-06  18:58:53   780543464       zalewski53   \n",
       "\n",
       "                name  \\\n",
       "0  Krzysztof Cichosz   \n",
       "1    Roland Zalewski   \n",
       "\n",
       "                                                                                                             tweet  \\\n",
       "0   Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych   \n",
       "1                                                               Polska Polityka: Sądy bardziej bezkarne niż w PRL    \n",
       "\n",
       "  emojis emoticons           mentions hashtags  \\\n",
       "0    NaN       NaN  ['tomsokolewicz']       []   \n",
       "1    NaN       NaN                 []       []   \n",
       "\n",
       "                                                                                                            reply_to  \\\n",
       "0  [{'user_id': '2367137142', 'username': 'KrzysztofCicho3'}, {'user_id': '244246777', 'username': 'TomSokolewicz'}]   \n",
       "1                                                               [{'user_id': '780543464', 'username': 'Zalewski53'}]   \n",
       "\n",
       "   replies_count  retweets_count  likes_count  \n",
       "0              0               0            0  \n",
       "1              0               0            0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_cols = ['new_id', 'date', 'time', 'user_id', 'username', 'name', 'tweet', 'emojis', 'emoticons',\n",
    "                 'mentions', 'hashtags', 'reply_to', 'replies_count', 'retweets_count', 'likes_count']\n",
    "\n",
    "df_infos = df_infos[relevant_cols]\n",
    "df_infos['new_id'] = df_infos['new_id'].astype(int)\n",
    "df_infos.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>wydźwięk</th>\n",
       "      <th>klucze</th>\n",
       "      <th>wyzywanie</th>\n",
       "      <th>grożenie</th>\n",
       "      <th>wykluczanie</th>\n",
       "      <th>odczłowieczanie</th>\n",
       "      <th>poniżanie</th>\n",
       "      <th>stygmatyzacja</th>\n",
       "      <th>szantaż</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>21:41:42</td>\n",
       "      <td>2367137142</td>\n",
       "      <td>krzysztofcicho3</td>\n",
       "      <td>Krzysztof Cichosz</td>\n",
       "      <td>Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['tomsokolewicz']</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>komuchów; gonić komuchów</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>18:58:53</td>\n",
       "      <td>780543464</td>\n",
       "      <td>zalewski53</td>\n",
       "      <td>Roland Zalewski</td>\n",
       "      <td>Polska Polityka: Sądy bardziej bezkarne niż w PRL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time     user_id         username               name  \\\n",
       "0  2014-06-06  21:41:42  2367137142  krzysztofcicho3  Krzysztof Cichosz   \n",
       "1  2014-06-06  18:58:53   780543464       zalewski53    Roland Zalewski   \n",
       "\n",
       "                                                                                                             tweet  \\\n",
       "0   Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych   \n",
       "1                                                               Polska Polityka: Sądy bardziej bezkarne niż w PRL    \n",
       "\n",
       "  emojis emoticons           mentions hashtags  ... id  wydźwięk  \\\n",
       "0    NaN       NaN  ['tomsokolewicz']       []  ...  0        -1   \n",
       "1    NaN       NaN                 []       []  ...  1        -1   \n",
       "\n",
       "                     klucze  wyzywanie  grożenie  wykluczanie odczłowieczanie  \\\n",
       "0  komuchów; gonić komuchów        1.0       NaN          NaN             NaN   \n",
       "1                       NaN        NaN       NaN          NaN             NaN   \n",
       "\n",
       "   poniżanie  stygmatyzacja  szantaż  \n",
       "0        NaN            NaN      NaN  \n",
       "1        NaN            NaN      NaN  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = df_infos.merge(df_annotated, left_on='new_id', right_on='id')\n",
    "df_combined = df_combined.drop(columns=['new_id'])\n",
    "df_combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'time', 'user_id', 'username', 'name', 'tweet', 'emojis',\n",
       "       'emoticons', 'mentions', 'hashtags', 'reply_to', 'replies_count',\n",
       "       'retweets_count', 'likes_count', 'id', 'wydźwięk', 'klucze',\n",
       "       'wyzywanie', 'grożenie', 'wykluczanie', 'odczłowieczanie', 'poniżanie',\n",
       "       'stygmatyzacja', 'szantaż'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>mentions</th>\n",
       "      <th>...</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>wydźwięk</th>\n",
       "      <th>klucze</th>\n",
       "      <th>wyzywanie</th>\n",
       "      <th>grożenie</th>\n",
       "      <th>wykluczanie</th>\n",
       "      <th>odczłowieczanie</th>\n",
       "      <th>poniżanie</th>\n",
       "      <th>stygmatyzacja</th>\n",
       "      <th>szantaż</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>21:41:42</td>\n",
       "      <td>2367137142</td>\n",
       "      <td>krzysztofcicho3</td>\n",
       "      <td>Krzysztof Cichosz</td>\n",
       "      <td>Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['tomsokolewicz']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>komuchów; gonić komuchów</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>18:58:53</td>\n",
       "      <td>780543464</td>\n",
       "      <td>zalewski53</td>\n",
       "      <td>Roland Zalewski</td>\n",
       "      <td>Polska Polityka: Sądy bardziej bezkarne niż w PRL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date      time     user_id         username               name  \\\n",
       "0   0  2014-06-06  21:41:42  2367137142  krzysztofcicho3  Krzysztof Cichosz   \n",
       "1   1  2014-06-06  18:58:53   780543464       zalewski53    Roland Zalewski   \n",
       "\n",
       "                                                                                                             tweet  \\\n",
       "0   Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych   \n",
       "1                                                               Polska Polityka: Sądy bardziej bezkarne niż w PRL    \n",
       "\n",
       "  emojis emoticons           mentions  ... likes_count wydźwięk  \\\n",
       "0    NaN       NaN  ['tomsokolewicz']  ...           0       -1   \n",
       "1    NaN       NaN                 []  ...           0       -1   \n",
       "\n",
       "                     klucze  wyzywanie  grożenie  wykluczanie odczłowieczanie  \\\n",
       "0  komuchów; gonić komuchów        1.0       NaN          NaN             NaN   \n",
       "1                       NaN        NaN       NaN          NaN             NaN   \n",
       "\n",
       "   poniżanie  stygmatyzacja  szantaż  \n",
       "0        NaN            NaN      NaN  \n",
       "1        NaN            NaN      NaN  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = df_combined[['id', 'date', 'time', 'user_id', 'username', 'name', 'tweet', 'emojis', 'emoticons',\n",
    "                           'mentions', 'hashtags', 'reply_to', 'replies_count', 'retweets_count', 'likes_count',\n",
    "                           'wydźwięk', 'klucze', 'wyzywanie', 'grożenie', 'wykluczanie',\n",
    "                           'odczłowieczanie', 'poniżanie', 'stygmatyzacja', 'szantaż']]\n",
    "df_combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('data/sady_main/sady_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class cardinalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wyzywanie</th>\n",
       "      <th>grożenie</th>\n",
       "      <th>wykluczanie</th>\n",
       "      <th>odczłowieczanie</th>\n",
       "      <th>poniżanie</th>\n",
       "      <th>stygmatyzacja</th>\n",
       "      <th>szantaż</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wyzywanie  grożenie  wykluczanie  odczłowieczanie  poniżanie  \\\n",
       "0          1         0            0                0          0   \n",
       "1          0         0            0                0          0   \n",
       "\n",
       "   stygmatyzacja  szantaż  number  \n",
       "0              0        0       0  \n",
       "1              0        0       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classes = df_combined[['wyzywanie', 'grożenie', 'wykluczanie', 'odczłowieczanie',\n",
    "                          'poniżanie', 'stygmatyzacja', 'szantaż']]\n",
    "df_classes = df_classes.notnull().astype('int')\n",
    "df_classes['number'] = df_classes.index\n",
    "df_classes.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERALLY** How many examples belong to each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number             15202\n",
       "stygmatyzacja        830\n",
       "poniżanie            700\n",
       "grożenie             393\n",
       "wyzywanie            242\n",
       "odczłowieczanie      174\n",
       "wykluczanie           94\n",
       "szantaż                6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs_classes = df_classes.sum().sort_values(ascending=False)\n",
    "srs_classes['number'] = df_classes['number'].count()\n",
    "srs_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number             100.000000\n",
       "stygmatyzacja        5.459808\n",
       "poniżanie            4.604657\n",
       "grożenie             2.585186\n",
       "wyzywanie            1.591896\n",
       "odczłowieczanie      1.144586\n",
       "wykluczanie          0.618340\n",
       "szantaż              0.039468\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(srs_classes/len(df_classes)*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'stygmatyzacja' (5.45%) and 'poniżanie' (4.60%) labels it's at most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SPECIFICALLY** How many examples belong to each combination of classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wyzywanie</th>\n",
       "      <th>grożenie</th>\n",
       "      <th>wykluczanie</th>\n",
       "      <th>odczłowieczanie</th>\n",
       "      <th>poniżanie</th>\n",
       "      <th>stygmatyzacja</th>\n",
       "      <th>szantaż</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>13654</td>\n",
       "      <td>89.817129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>361</td>\n",
       "      <td>2.374688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>251</td>\n",
       "      <td>1.651099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>197</td>\n",
       "      <td>1.295882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>179</td>\n",
       "      <td>1.177477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>0.697277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>0.374951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>0.282858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0.263123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>0.236811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0.210499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0.210499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0.151296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.131562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.131562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.098671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0.085515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0.085515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.072359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.065781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.052625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.046047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.039468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.039468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.032890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.032890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.026312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.026312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.026312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.026312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.019734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.019734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.019734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.019734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                number  \\\n",
       "wyzywanie grożenie wykluczanie odczłowieczanie poniżanie stygmatyzacja szantaż           \n",
       "0         0        0           0               0         0             0         13654   \n",
       "                                                         1             0           361   \n",
       "                                               1         0             0           251   \n",
       "                                                         1             0           197   \n",
       "          1        0           0               0         0             0           179   \n",
       "                                                         1             0           106   \n",
       "1         0        0           0               1         0             0            57   \n",
       "                                               0         0             0            43   \n",
       "                               1               1         1             0            40   \n",
       "0         0        0           1               0         0             0            36   \n",
       "          1        1           0               0         0             0            32   \n",
       "1         0        0           0               1         1             0            32   \n",
       "0         0        0           1               1         0             0            23   \n",
       "          1        0           0               1         0             0            20   \n",
       "1         0        0           0               0         1             0            20   \n",
       "                               1               1         0             0            15   \n",
       "0         0        1           0               0         0             0            13   \n",
       "                   0           1               0         1             0            13   \n",
       "                                               1         1             0            11   \n",
       "                   1           0               1         0             0            10   \n",
       "          1        0           0               1         1             0             8   \n",
       "1         0        0           1               0         1             0             7   \n",
       "0         0        1           0               0         1             0             6   \n",
       "          1        0           1               0         1             0             6   \n",
       "1         1        0           0               0         0             0             5   \n",
       "0         1        0           1               1         0             0             5   \n",
       "1         1        0           0               1         0             0             4   \n",
       "          0        1           0               1         1             0             4   \n",
       "0         1        1           0               0         1             0             4   \n",
       "                   0           1               0         0             0             4   \n",
       "                   1           0               1         1             0             3   \n",
       "          0        0           0               0         0             1             3   \n",
       "          1        0           1               1         1             0             3   \n",
       "          0        1           0               1         1             0             3   \n",
       "          1        1           1               0         0             0             2   \n",
       "1         1        1           0               1         0             0             2   \n",
       "                                               0         0             0             2   \n",
       "          0        1           1               1         0             0             2   \n",
       "0         0        1           1               1         0             0             2   \n",
       "          1        0           0               0         0             1             2   \n",
       "1         0        1           0               1         0             0             1   \n",
       "                                               0         0             0             1   \n",
       "0         0        1           1               1         1             0             1   \n",
       "1         0        1           1               1         1             0             1   \n",
       "0         0        1           1               0         0             0             1   \n",
       "1         1        0           0               0         1             0             1   \n",
       "                                               1         1             0             1   \n",
       "          0        0           1               0         0             0             1   \n",
       "0         1        1           0               1         0             0             1   \n",
       "1         1        1           0               1         0             1             1   \n",
       "                                                         1             0             1   \n",
       "                               1               1         1             0             1   \n",
       "\n",
       "                                                                                        %  \n",
       "wyzywanie grożenie wykluczanie odczłowieczanie poniżanie stygmatyzacja szantaż             \n",
       "0         0        0           0               0         0             0        89.817129  \n",
       "                                                         1             0         2.374688  \n",
       "                                               1         0             0         1.651099  \n",
       "                                                         1             0         1.295882  \n",
       "          1        0           0               0         0             0         1.177477  \n",
       "                                                         1             0         0.697277  \n",
       "1         0        0           0               1         0             0         0.374951  \n",
       "                                               0         0             0         0.282858  \n",
       "                               1               1         1             0         0.263123  \n",
       "0         0        0           1               0         0             0         0.236811  \n",
       "          1        1           0               0         0             0         0.210499  \n",
       "1         0        0           0               1         1             0         0.210499  \n",
       "0         0        0           1               1         0             0         0.151296  \n",
       "          1        0           0               1         0             0         0.131562  \n",
       "1         0        0           0               0         1             0         0.131562  \n",
       "                               1               1         0             0         0.098671  \n",
       "0         0        1           0               0         0             0         0.085515  \n",
       "                   0           1               0         1             0         0.085515  \n",
       "                                               1         1             0         0.072359  \n",
       "                   1           0               1         0             0         0.065781  \n",
       "          1        0           0               1         1             0         0.052625  \n",
       "1         0        0           1               0         1             0         0.046047  \n",
       "0         0        1           0               0         1             0         0.039468  \n",
       "          1        0           1               0         1             0         0.039468  \n",
       "1         1        0           0               0         0             0         0.032890  \n",
       "0         1        0           1               1         0             0         0.032890  \n",
       "1         1        0           0               1         0             0         0.026312  \n",
       "          0        1           0               1         1             0         0.026312  \n",
       "0         1        1           0               0         1             0         0.026312  \n",
       "                   0           1               0         0             0         0.026312  \n",
       "                   1           0               1         1             0         0.019734  \n",
       "          0        0           0               0         0             1         0.019734  \n",
       "          1        0           1               1         1             0         0.019734  \n",
       "          0        1           0               1         1             0         0.019734  \n",
       "          1        1           1               0         0             0         0.013156  \n",
       "1         1        1           0               1         0             0         0.013156  \n",
       "                                               0         0             0         0.013156  \n",
       "          0        1           1               1         0             0         0.013156  \n",
       "0         0        1           1               1         0             0         0.013156  \n",
       "          1        0           0               0         0             1         0.013156  \n",
       "1         0        1           0               1         0             0         0.006578  \n",
       "                                               0         0             0         0.006578  \n",
       "0         0        1           1               1         1             0         0.006578  \n",
       "1         0        1           1               1         1             0         0.006578  \n",
       "0         0        1           1               0         0             0         0.006578  \n",
       "1         1        0           0               0         1             0         0.006578  \n",
       "                                               1         1             0         0.006578  \n",
       "          0        0           1               0         0             0         0.006578  \n",
       "0         1        1           0               1         0             0         0.006578  \n",
       "1         1        1           0               1         0             1         0.006578  \n",
       "                                                         1             0         0.006578  \n",
       "                               1               1         1             0         0.006578  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfagg_classes = df_classes.groupby(['wyzywanie', 'grożenie', 'wykluczanie', 'odczłowieczanie',\n",
    "                                  'poniżanie', 'stygmatyzacja', 'szantaż'])\\\n",
    "                                  .count().sort_values(by='number', ascending=False)\n",
    "dfagg_classes['%'] = dfagg_classes['number']/len(df_classes)*100\n",
    "dfagg_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combinations of labels single 'stygmatyzacja' (2.37%) and 'stygmatyzacja' with 'poniżanie' (1.65%) it's at most"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hateful phrases analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>klucze</th>\n",
       "      <th>wyzywanie</th>\n",
       "      <th>grożenie</th>\n",
       "      <th>wykluczanie</th>\n",
       "      <th>odczłowieczanie</th>\n",
       "      <th>poniżanie</th>\n",
       "      <th>stygmatyzacja</th>\n",
       "      <th>szantaż</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>komuchów; gonić komuchów</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>odbierajmy [...] bałwanom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spocona świnia; świnia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>durne angielskie przepisy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Kwaśniewski [...] idiota</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       klucze  wyzywanie  grożenie  wykluczanie  \\\n",
       "0    komuchów; gonić komuchów          1         0            0   \n",
       "2   odbierajmy [...] bałwanom          0         0            0   \n",
       "19     spocona świnia; świnia          0         0            0   \n",
       "41  durne angielskie przepisy          0         0            0   \n",
       "48   Kwaśniewski [...] idiota          1         0            0   \n",
       "\n",
       "    odczłowieczanie  poniżanie  stygmatyzacja  szantaż  \n",
       "0                 0          0              0        0  \n",
       "2                 0          1              0        0  \n",
       "19                0          1              0        0  \n",
       "41                0          1              0        0  \n",
       "48                0          1              0        0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrases = df_combined[['klucze', 'wyzywanie', 'grożenie', 'wykluczanie',\n",
    "                          'odczłowieczanie', 'poniżanie', 'stygmatyzacja', 'szantaż']]\n",
    "df_phrases = df_phrases.notnull().astype('int')\n",
    "df_phrases['klucze'] = df_combined['klucze']\n",
    "df_phrases = df_phrases.dropna()\n",
    "df_phrases['klucze'] = list([phr.replace('[..]', '[...]') for phr in df_phrases['klucze']])\n",
    "\n",
    "df_phrases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert list-like column elements to separate rows: [link](https://cmdlinetips.com/2020/06/pandas-explode-convert-list-like-column-elements-to-separate-rows/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>klucze</th>\n",
       "      <th>wyzywanie</th>\n",
       "      <th>grożenie</th>\n",
       "      <th>wykluczanie</th>\n",
       "      <th>odczłowieczanie</th>\n",
       "      <th>poniżanie</th>\n",
       "      <th>stygmatyzacja</th>\n",
       "      <th>szantaż</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>komuchów</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gonić komuchów</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>odbierajmy [...] bałwanom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spocona świnia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>świnia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       klucze  wyzywanie  grożenie  wykluczanie  \\\n",
       "0                    komuchów          1         0            0   \n",
       "0              gonić komuchów          1         0            0   \n",
       "2   odbierajmy [...] bałwanom          0         0            0   \n",
       "19             spocona świnia          0         0            0   \n",
       "19                     świnia          0         0            0   \n",
       "\n",
       "    odczłowieczanie  poniżanie  stygmatyzacja  szantaż  \n",
       "0                 0          0              0        0  \n",
       "0                 0          0              0        0  \n",
       "2                 0          1              0        0  \n",
       "19                0          1              0        0  \n",
       "19                0          1              0        0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrases['klucze'] = list([k.split(';') for k in df_phrases['klucze']])\n",
    "df_phrases = df_phrases.explode('klucze')\n",
    "df_phrases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['komuchów',\n",
       " ' gonić komuchów',\n",
       " 'Kwaśniewski [...] idiota',\n",
       " 'pojebało kogoś',\n",
       " 'politycy [...] kłapania dziobem']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phr_wyz = list(df_phrases[df_phrases['wyzywanie'] == 1]['klucze'])\n",
    "phr_wyz[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sądy [...] skasują',\n",
       " 'bomb[...] domy podejrzanych',\n",
       " 'policzek [...] nie zaszkodzi',\n",
       " 'że was zajebiemy',\n",
       " 'sądy gówniane']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phr_groz = list(df_phrases[df_phrases['grożenie'] == 1]['klucze'])\n",
    "phr_groz[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ryj [...] zakazany',\n",
       " 'prezydent nie wart szacunku',\n",
       " ' Premiar morderca, zdrajca',\n",
       " 'wypierdoliliśmy ją z roboty',\n",
       " ' nie ma kasy na sądy [...] nam nie skoczy']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phr_wyk = list(df_phrases[df_phrases['wykluczanie'] == 1]['klucze'])\n",
    "phr_wyk[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['komisja śledcza z pachołkami bez wiedzy',\n",
       " 'prezydent nie wart szacunku',\n",
       " ' Premiar morderca, zdrajca',\n",
       " 'bomb[...] domy podejrzanych',\n",
       " 'esbeckie złogi']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phr_odcz = list(df_phrases[df_phrases['odczłowieczanie'] == 1]['klucze'])\n",
    "phr_odcz[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['odbierajmy [...] bałwanom',\n",
       " 'spocona świnia',\n",
       " ' świnia',\n",
       " 'durne angielskie przepisy',\n",
       " 'Kwaśniewski [...] idiota']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phr_pon = list(df_phrases[df_phrases['poniżanie'] == 1]['klucze'])\n",
    "phr_pon[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sądy [...] to zbytek',\n",
       " ' #Józefmoneta',\n",
       " 'PiS gwałci żeby nie robić aborcji',\n",
       " 'ryj [...] zakazany',\n",
       " 'politycy [...] kłapania dziobem']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phr_styg = list(df_phrases[df_phrases['stygmatyzacja'] == 1]['klucze'])\n",
    "phr_styg[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wypierdalaj stąd, bo zaliczysz zgon',\n",
       " ' jesteś kurwą, wypierdalaj',\n",
       " ' wypierdalaj',\n",
       " 'jak nie odsuniecie [...] to zamkniemy was w pierdlu',\n",
       " 'jak dalej będziesz tworzyć trudne sądy [...] przez Ciebie przejdę ząłamanie nerwowe']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phr_szan = list(df_phrases[df_phrases['szantaż'] == 1]['klucze'])\n",
    "phr_szan[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "morf = morfeusz2.Morfeusz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    analysis = morf.analyse(text.replace('#', ''))\n",
    "    lemmas = list([])\n",
    "    \n",
    "    i, j, interp = analysis[0]\n",
    "    last_ij, last_lemma = (i, j), interp[1].split(':')[0].lower()\n",
    "    lemmas.append(last_lemma)\n",
    "    \n",
    "    for i, j, interp in analysis[1:]:\n",
    "        lemma = interp[1].split(':')[0].lower()\n",
    "        if not (last_ij == (i, j) and last_lemma == lemma):\n",
    "            lemmas.append(lemma)\n",
    "        \n",
    "        last_ij = (i, j)\n",
    "        last_lemma = lemma\n",
    "    \n",
    "    lemm_text = ' '.join(lemmas)\n",
    "    lemm_text = lemm_text.replace(' [ . . . ]', '')\n",
    "    \n",
    "    return lemm_text\n",
    "\n",
    "def get_lemmatized_phrases(phrases, save_file=None):\n",
    "    lemm_phrases = list([])\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        lemm_phrase = lemmatize_text(phrase)\n",
    "        if lemm_phrase not in lemm_phrases:\n",
    "            lemm_phrases.append(lemm_phrase)\n",
    "    \n",
    "    if save_file:\n",
    "        with open(save_file, 'w') as f:\n",
    "            for lemm_phrase in lemm_phrases:\n",
    "                f.writelines(lemm_phrase + '\\n')\n",
    "    \n",
    "    return lemm_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sąd cycek zrobić ja pierdolić'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_text('sądy cycki zrobiła ja pierdolę')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['komuch',\n",
       " 'gonić komuch',\n",
       " 'kwaśniewski idiota',\n",
       " 'pojebać kto ktoś być',\n",
       " 'polityk kłapać dziób']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmphr_wyz = get_lemmatized_phrases(phr_wyz, save_file='data/hateful_phrases/lemm_wyz.txt')\n",
    "lemmphr_wyz[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sąd skasować',\n",
       " 'bomba dom podejrzeć podejrzany podejrzana',\n",
       " 'policzek nie on nie zaszkodzić',\n",
       " 'że wy zajebać',\n",
       " 'sąd gówniany']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmphr_groz = get_lemmatized_phrases(phr_groz, save_file='data/hateful_phrases/lemm_groz.txt')\n",
    "lemmphr_groz[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ryj ryć zakazać zakazany',\n",
       " 'prezydent nie on nie wart warta wart szacunek',\n",
       " 'premiara morderca , zdrajca',\n",
       " 'wypierdolić być on z roboty robot robota',\n",
       " 'nie on nie mój mieć kasa na sąd my nie on nie skoczyć']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmphr_wyk = get_lemmatized_phrases(phr_wyk, save_file='data/hateful_phrases/lemm_wyk.txt')\n",
    "lemmphr_wyk[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['komisja śledczy z pachołek bez beza wiedza',\n",
       " 'prezydent nie on nie wart warta wart szacunek',\n",
       " 'premiara morderca , zdrajca',\n",
       " 'bomba dom podejrzeć podejrzany podejrzana',\n",
       " 'esbecki złóg']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmphr_odcz = get_lemmatized_phrases(phr_odcz, save_file='data/hateful_phrases/lemm_odcz.txt')\n",
    "lemmphr_odcz[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['odbierać bałwan',\n",
       " 'spocić świnia świni',\n",
       " 'świnia świni',\n",
       " 'durny angielski przepis',\n",
       " 'kwaśniewski idiota']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmphr_pon = get_lemmatized_phrases(phr_pon, save_file='data/hateful_phrases/lemm_pon.txt')\n",
    "lemmphr_pon[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sąd ten to zbytek',\n",
       " 'józefmoneta',\n",
       " 'pis pisa gwałcić żeby nie on nie robić aborcja',\n",
       " 'ryj ryć zakazać zakazany',\n",
       " 'polityk kłapać dziób']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmphr_styg = get_lemmatized_phrases(phr_styg, save_file='data/hateful_phrases/lemm_styg.txt')\n",
    "lemmphr_styg[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wypierdalać stąd , bo zaliczyć zgon',\n",
       " 'być kurwa , wypierdalać',\n",
       " 'wypierdalać',\n",
       " 'jak jaka jak nie on nie odsunąć ten to zamknąć wy w pierdel',\n",
       " 'jak jaka jak daleko dalej być tworzyć trudny sąd przez ty przejść ząłamanie nerwowy']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmphr_szan = get_lemmatized_phrases(phr_szan, save_file='data/hateful_phrases/lemm_szan.txt')\n",
    "lemmphr_szan[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonymic\n",
    "Get negative or neutral sentiment synonyms for each lemmatized word and perform cartesian product over listed lists of word synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_wordnet = PlwnxmlParser('models/plwordnet_3_0/plwordnet-3.0.xml').read_wordnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonymic_phrases(phrase, lemmatized=True, stopwords=[]):\n",
    "    synonymic_phrases_options = list([])\n",
    "    p = phrase if lemmatized else lemmatize_text(phrase)\n",
    "    \n",
    "    lemm_words = list([w for w in p.split(' ') if w not in stopwords])\n",
    "    \n",
    "    for lemm_word in lemm_words:\n",
    "        lemm_word_options = list([])\n",
    "        for lemm in pl_wordnet.lemma(lemm_word):\n",
    "            for synset in lemm.synsets:\n",
    "                for lu in synset.lexical_units:\n",
    "                    if lu.sentiment in ['- m', '- s'] and lu.name not in lemm_word_options:\n",
    "                        lemm_word_options.append(lu.name)\n",
    "        \n",
    "        if len(lemm_word_options) == 0:\n",
    "            lemm_word_options.append(lemm_word)\n",
    "        synonymic_phrases_options.append(lemm_word_options)\n",
    "    \n",
    "    options = list(itertools.product(*synonymic_phrases_options))\n",
    "    options = list([' '.join(option) for option in options])\n",
    "    if p in options:\n",
    "        options.remove(p)\n",
    "    \n",
    "    return options\n",
    "\n",
    "def get_synonymic_phrases(phrases, lemmatized=True, stopwords=[], save_file=None):\n",
    "    all_syn_phrases = list([])\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        syn_phrases = synonymic_phrases(phrase, lemmatized=lemmatized, stopwords=stopwords)\n",
    "        for sp in syn_phrases:\n",
    "            if sp not in all_syn_phrases:\n",
    "                all_syn_phrases.append(sp)\n",
    "    \n",
    "    if save_file:\n",
    "        with open(save_file, 'w') as f:\n",
    "            for syn_phrase in all_syn_phrases:\n",
    "                f.writelines(syn_phrase + '\\n')\n",
    "    \n",
    "    return all_syn_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymic_phrases('faszyzm sąd faszyzm sąd', stopwords=polish_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pojebać',\n",
       " 'czuj czuja czuć ?',\n",
       " 'prezydent wart warta wart szacunek',\n",
       " 'ch . m miasto morze męski metr . wiek wielki wiersz wieś wyspa . d dawny dom dzień .',\n",
       " 'chuj dupa']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synphr_wyz = get_synonymic_phrases(lemmphr_wyz, stopwords=polish_stopwords,\n",
    "                                   save_file='data/hateful_phrases/syn_wyz.txt')\n",
    "synphr_wyz[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['policzek zaszkodzić',\n",
       " 'zajebać',\n",
       " 'ruski ruskie ruski wypieprzyć',\n",
       " 'prezydent czarna czarny dupa',\n",
       " 'wyczyścić sędzia']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synphr_groz = get_synonymic_phrases(lemmphr_groz, stopwords=polish_stopwords,\n",
    "                                    save_file='data/hateful_phrases/syn_groz.txt')\n",
    "synphr_groz[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prezydent wart warta wart szacunek',\n",
       " 'wypierdolić roboty robot robota',\n",
       " 'mieć kasa sąd skoczyć',\n",
       " 'ruski ruskie ruski wypieprzyć',\n",
       " 'wyczyścić sędzia']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synphr_wyk = get_synonymic_phrases(lemmphr_wyk, stopwords=polish_stopwords,\n",
    "                                   save_file='data/hateful_phrases/syn_wyk.txt')\n",
    "synphr_wyk[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['komisja śledczy pachołek beza wiedza',\n",
       " 'prezydent wart warta wart szacunek',\n",
       " 'esbecki złóg / psl',\n",
       " 'sąd cycek zrobić pierdolić',\n",
       " 'chcieć menda']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synphr_odcz = get_synonymic_phrases(lemmphr_odcz, stopwords=polish_stopwords,\n",
    "                                    save_file='data/hateful_phrases/syn_odcz.txt')\n",
    "synphr_odcz[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sąd zbytek',\n",
       " 'pis pisa gwałcić robić aborcja',\n",
       " 'komisja śledczy pachołek beza wiedza',\n",
       " 'czuj czuja czuć ?',\n",
       " 'prezydent wart warta wart szacunek']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synphr_pon = get_synonymic_phrases(lemmphr_pon, stopwords=polish_stopwords,\n",
    "                                   save_file='data/hateful_phrases/syn_pon.txt')\n",
    "synphr_pon[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sąd zbytek',\n",
       " 'pis pisa gwałcić robić aborcja',\n",
       " 'prezydent wart warta wart szacunek',\n",
       " 'sąd patologia pierdolić',\n",
       " 'jews kraść milion']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synphr_styg = get_synonymic_phrases(lemmphr_styg, stopwords=polish_stopwords,\n",
    "                                    save_file='data/hateful_phrases/syn_styg.txt')\n",
    "synphr_styg[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wypierdalać stąd , zaliczyć zgon',\n",
       " 'kurwa , wypierdalać',\n",
       " 'jaka odsunąć zamknąć pierdel',\n",
       " 'jaka dalej tworzyć trudny sąd przejść ząłamanie nerwowy',\n",
       " 'akta akt stół alba morda kubełl']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synphr_szan = get_synonymic_phrases(lemmphr_szan, stopwords=polish_stopwords,\n",
    "                                    save_file='data/hateful_phrases/syn_szan.txt')\n",
    "synphr_szan[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrases appearance calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to calculate phrase appearance coefficient (PAC) in text?**\n",
    "\n",
    "1. Split by whitespace lemmatized text and phrase to separate words.\n",
    "2. Delete all stopwords and interpunction symbols from text and phrase.\n",
    "3. For each word in phrase list all positions of phrase word in examined text. If no positions found, then omit this word.\n",
    "4. Get all possible phrase words orders in examined text i.e. perform cartesian product for positions lists.\n",
    "5. For each possible order:\n",
    "    1. Form list of n positions into n-1 pairs.\n",
    "    2. For each pair assign (1) if first element is smaller than second (ascending order) else (-1)\n",
    "    3. Sum all assignations and divide the total by number of words in phrase (n) minus 1.\n",
    "6. Return minimum, mean and maximum score.\n",
    "\n",
    "**EXAMPLE 1.**:<br />\n",
    "text: *Wróciły pisowskie trójki sądy doraźne koksowniki i SKOTy, do tego PiS gwałci żeby nie robić aborcji* <br />\n",
    "phrase: *PiS gwałci żeby nie robić aborcji*<br />\n",
    "<br />\n",
    "Lemmatized text and phrase without stopwords:<br />\n",
    "*wrócić(0) pisowski(1) trójka(2) sąd(3) doraźny(4) koksownik(5) skot(6) PiS(7) Pis(8) Pisa(9) gwałcić(10) żeby(11) robić(12) aborcja(13)*<br />\n",
    "*PiS[7,] Pis[8,] Pisa[9,] gwałcić[10,] żeby[11,] robić[12,] aborcja[13,]*<br />\n",
    "**n=7**<br />\n",
    "<br />\n",
    "Possible orders:<br />\n",
    "--> (7, 8, 9, 10, 11, 12, 13): coeff=((+1) + (+1) + (+1) + (+1) + (+1) + (+1))/(7 - 1) = 1.0<br />\n",
    "<br />\n",
    "Results: **MIN=1.0 MEAN=1.0 MAX=1.0**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**EXAMPLE 2.**:<br />\n",
    "text: *Faszystowskie sądy ach faszystowskie sądy*<br/>\n",
    "phrase : *Ach faszystowskie sądy fałszywe*<br />\n",
    "<br />\n",
    "Lemmatized text and phrase without stopwords:<br />\n",
    "*faszyzm(0) sąd(1) faszyzm(2) sąd(3)*<br />\n",
    "*faszyzm[0, 2,] sąd[1, 3,] fałsz[]*<br />\n",
    "**n=3**<br />\n",
    "<br />\n",
    "Possible orders:<br />\n",
    "--> (0, 1): coeff=((+1))/(3-1)=0.5<br />\n",
    "--> (0, 3): coeff=((+1))/(3-1)=0.5<br />\n",
    "--> (2, 1): coeff=((-1))/(3-1)=-0.5<br />\n",
    "--> (2, 3): coeff=((+1))/(3-1)=0.5<br />\n",
    "<br />\n",
    "Results: **MIN=-0.5 MEAN=0.25 MAX=0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_PAC(text, phrase, lemmatized=False, stopwords=[]):\n",
    "    \n",
    "    t = text if lemmatized else lemmatize_text(text)\n",
    "    p = phrase if lemmatized else lemmatize_text(phrase)\n",
    "    \n",
    "    t_words = list(filter(lambda x: x not in stopwords, t.split(' ')))\n",
    "    p_words = list(filter(lambda x: x not in stopwords, p.split(' ')))\n",
    "    \n",
    "    assert (len(t_words) > 0), 'The examined text must have at least one non-stopword word!'\n",
    "    \n",
    "    if len(p_words) > 1:\n",
    "        occurences = list([[i for i, x in enumerate(t_words) if x == p_w] for p_w in p_words])\n",
    "        occurences = list([o for o in occurences if len(o) > 0])\n",
    "\n",
    "        orders = list(itertools.product(*occurences))\n",
    "        order_pairs_list = list([[tuple((o[i], o[i+1])) for i, oi in enumerate(o[:-1])] for o in orders])\n",
    "\n",
    "        coeffs = list([sum([1. if op[0]<op[1] else -1. for op in ops])/(len(p_words) - 1)\n",
    "                       for ops in order_pairs_list])\n",
    "\n",
    "        return (np.min(coeffs), np.mean(coeffs), np.max(coeffs))\n",
    "    elif len(p_words) == 1:\n",
    "        return (1., 1., 1.) if p_words[0] in t_words else (0., 0., 0.)\n",
    "    else:\n",
    "        return (0., 0., 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Wróciły pisowskie trójki sądy doraźne koksowniki i SKOTy, do tego PiS gwałci żeby nie robić aborcji'\n",
    "phrase = 'PiS gwałci żeby nie robić aborcji'\n",
    "\n",
    "calculate_PAC(text, phrase, stopwords=polish_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 0.25, 0.5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Faszystowskie sądy ach faszystowskie sądy'\n",
    "phrase = 'Ach faszystowskie sądy fałszywe'\n",
    "\n",
    "calculate_PAC(text, phrase, stopwords=polish_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate PAC score for all tweets.**\n",
    "\n",
    "1. Load relevant data with sanitized tweets with classes and all hateful phrases.\n",
    "2. For each tweet:\n",
    "    1. For each hate type:\n",
    "        1. Calculate PAC scores (min, mean, max) for every phrase which belongs to certain hate type\n",
    "        2. Get means of minimum, mean and maximum PAC scores\n",
    "        3. Write calculations into dictionary\n",
    "    2. Write all hate types dictionary values into .csv row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_HATE_TYPES = ['wyzywanie', 'grożenie', 'wykluczanie', 'odczłowieczanie', 'poniżanie',\n",
    "                   'stygmatyzacja', 'szantaż']\n",
    "HATE_TYPES = ['wyz', 'groz', 'wyk', 'odcz', 'pon', 'styg', 'szan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_phrases = list([\n",
    "    lemmphr_wyz, lemmphr_groz, lemmphr_wyk, lemmphr_odcz, lemmphr_pon, lemmphr_styg, lemmphr_szan\n",
    "])\n",
    "synonymic_phrases = list([\n",
    "    synphr_wyz, synphr_groz, synphr_wyk, synphr_odcz, synphr_pon, synphr_styg, synphr_szan\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>wyzywanie</th>\n",
       "      <th>grożenie</th>\n",
       "      <th>wykluczanie</th>\n",
       "      <th>odczłowieczanie</th>\n",
       "      <th>poniżanie</th>\n",
       "      <th>stygmatyzacja</th>\n",
       "      <th>szantaż</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Polska Polityka: Sądy bardziej bezkarne niż w PRL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "\n",
       "                                                                                                             tweet  \\\n",
       "0   Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych   \n",
       "1                                                               Polska Polityka: Sądy bardziej bezkarne niż w PRL    \n",
       "\n",
       "   wyzywanie  grożenie  wykluczanie  odczłowieczanie  poniżanie  \\\n",
       "0          1         0            0                0          0   \n",
       "1          0         0            0                0          0   \n",
       "\n",
       "   stygmatyzacja  szantaż  \n",
       "0              0        0  \n",
       "1              0        0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_combined[['id', 'tweet', 'wyzywanie', 'grożenie', 'wykluczanie', 'odczłowieczanie', 'poniżanie',\n",
    "                       'stygmatyzacja', 'szantaż']]\n",
    "ids  = df_data['id']\n",
    "tweets = df_data['tweet']\n",
    "df_data = df_data.notnull().astype('int')\n",
    "df_data['id'] = ids\n",
    "df_data['tweet'] = tweets\n",
    "del ids, tweets\n",
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>wyzywanie</th>\n",
       "      <th>grożenie</th>\n",
       "      <th>wykluczanie</th>\n",
       "      <th>odczłowieczanie</th>\n",
       "      <th>poniżanie</th>\n",
       "      <th>stygmatyzacja</th>\n",
       "      <th>szantaż</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dokładnie ! dlatego trzeba komuch gonić przed sąd póki żyć . i miąć otworzyć otwarty oko oczyć na komuch zakamuflować</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Polska Polityka: Sądy bardziej bezkarne niż w PRL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>polska polski polityka polityk  sąd bardzo bezkarny niż niża niżyć nizać niż w prl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "\n",
       "                                                                                                             tweet  \\\n",
       "0   Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych   \n",
       "1                                                               Polska Polityka: Sądy bardziej bezkarne niż w PRL    \n",
       "\n",
       "   wyzywanie  grożenie  wykluczanie  odczłowieczanie  poniżanie  \\\n",
       "0          1         0            0                0          0   \n",
       "1          0         0            0                0          0   \n",
       "\n",
       "   stygmatyzacja  szantaż  \\\n",
       "0              0        0   \n",
       "1              0        0   \n",
       "\n",
       "                                                                                                              lemmatized  \n",
       "0  dokładnie ! dlatego trzeba komuch gonić przed sąd póki żyć . i miąć otworzyć otwarty oko oczyć na komuch zakamuflować  \n",
       "1                                     polska polski polityka polityk  sąd bardzo bezkarny niż niża niżyć nizać niż w prl  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm_tweets = list([lemmatize_text(tweet) for tweet in df_data['tweet']])\n",
    "df_data['lemmatized'] = lemm_tweets\n",
    "del lemm_tweets\n",
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAC_SCORES_PATH = 'data/sady_main/sady_pac_scores.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PAC_SCORES_PATH):\n",
    "    with open(PAC_SCORES_PATH, 'w') as f:\n",
    "        csv.writer(f).writerow([\n",
    "            'id', 'tweet',\n",
    "            'wyz_PAC_min', 'wyz_PAC_mean', 'wyz_PAC_max', 'wyz_label',\n",
    "            'groz_PAC_min', 'groz_PAC_mean', 'groz_PAC_max', 'groz_label',\n",
    "            'wyk_PAC_min', 'wyk_PAC_mean', 'wyk_PAC_max', 'wyk_label',\n",
    "            'odcz_PAC_min', 'odcz_PAC_mean', 'odcz_PAC_max', 'odcz_label', \n",
    "            'pon_PAC_min', 'pon_PAC_mean', 'pon_PAC_max', 'pon_label',\n",
    "            'styg_PAC_min', 'styg_PAC_mean', 'styg_PAC_max', 'styg_label',\n",
    "            'szan_PAC_min', 'szan_PAC_mean', 'szan_PAC_max', 'szan_label',\n",
    "        ])\n",
    "\n",
    "    for _id, tweet in tqdm(df_data.iterrows(), total=len(df_data)):\n",
    "        scores = dict({})\n",
    "        \n",
    "        for hate_type, l_phrases, s_phrases in zip(HATE_TYPES, lemmatized_phrases, synonymic_phrases):\n",
    "            sc_min, sc_mean, sc_max = list([]), list([]), list([])\n",
    "\n",
    "            for l_phrase in l_phrases:\n",
    "                mn, mean, mx = calculate_PAC(tweet['lemmatized'], l_phrase, lemmatized=True,\n",
    "                                             stopwords=polish_stopwords)\n",
    "                sc_min.append(mn)\n",
    "                sc_mean.append(mean)\n",
    "                sc_max.append(mx)\n",
    "\n",
    "            for s_phrase in s_phrases:\n",
    "                mn, mean, mx = calculate_PAC(tweet['lemmatized'], s_phrase, lemmatized=True,\n",
    "                                             stopwords=polish_stopwords)\n",
    "                sc_min.append(mn)\n",
    "                sc_mean.append(mean)\n",
    "                sc_max.append(mx)\n",
    "\n",
    "            scores[f'{hate_type}_min'] = np.min(sc_min)\n",
    "            scores[f'{hate_type}_mean'] = np.mean(sc_mean)\n",
    "            scores[f'{hate_type}_max'] = np.max(sc_max)\n",
    "            del sc_min, sc_mean, sc_max\n",
    "        \n",
    "        with open(PAC_SCORES_PATH, 'a') as f:\n",
    "            csv.writer(f).writerow([\n",
    "                _id, tweet['tweet'],\n",
    "                scores['wyz_min'], scores['wyz_mean'], scores['wyz_max'], tweet['wyzywanie'],\n",
    "                scores['groz_min'], scores['groz_mean'], scores['groz_max'], tweet['grożenie'],\n",
    "                scores['wyk_min'], scores['wyk_mean'], scores['wyk_max'], tweet['wykluczanie'],\n",
    "                scores['odcz_min'], scores['odcz_mean'], scores['odcz_max'], tweet['odczłowieczanie'],\n",
    "                scores['pon_min'], scores['pon_mean'], scores['pon_max'], tweet['poniżanie'],\n",
    "                scores['styg_min'], scores['styg_mean'], scores['styg_max'], tweet['stygmatyzacja'],\n",
    "                scores['szan_min'], scores['szan_mean'], scores['szan_max'], tweet['szantaż'],\n",
    "            ])\n",
    "        del scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>wyz_PAC_min</th>\n",
       "      <th>wyz_PAC_mean</th>\n",
       "      <th>wyz_PAC_max</th>\n",
       "      <th>wyz_label</th>\n",
       "      <th>groz_PAC_min</th>\n",
       "      <th>groz_PAC_mean</th>\n",
       "      <th>groz_PAC_max</th>\n",
       "      <th>groz_label</th>\n",
       "      <th>...</th>\n",
       "      <th>pon_PAC_max</th>\n",
       "      <th>pon_label</th>\n",
       "      <th>styg_PAC_min</th>\n",
       "      <th>styg_PAC_mean</th>\n",
       "      <th>styg_PAC_max</th>\n",
       "      <th>styg_label</th>\n",
       "      <th>szan_PAC_min</th>\n",
       "      <th>szan_PAC_mean</th>\n",
       "      <th>szan_PAC_max</th>\n",
       "      <th>szan_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.002833</td>\n",
       "      <td>-0.002833</td>\n",
       "      <td>-0.002833</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Polska Polityka: Sądy bardziej bezkarne niż w PRL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "\n",
       "                                                                                                             tweet  \\\n",
       "0   Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych   \n",
       "1                                                               Polska Polityka: Sądy bardziej bezkarne niż w PRL    \n",
       "\n",
       "   wyz_PAC_min  wyz_PAC_mean  wyz_PAC_max  wyz_label  groz_PAC_min  \\\n",
       "0    -0.000129      0.002574     0.005277          1     -0.002833   \n",
       "1     0.000000      0.000000     0.000000          0     -0.000527   \n",
       "\n",
       "   groz_PAC_mean  groz_PAC_max  groz_label  ...  pon_PAC_max  pon_label  \\\n",
       "0      -0.002833     -0.002833           0  ...     0.000440          0   \n",
       "1      -0.000527     -0.000527           0  ...    -0.004546          0   \n",
       "\n",
       "   styg_PAC_min  styg_PAC_mean  styg_PAC_max  styg_label  szan_PAC_min  \\\n",
       "0     -0.000614       0.000698      0.002010           0           0.0   \n",
       "1      0.000097       0.000097      0.000097           0           0.0   \n",
       "\n",
       "   szan_PAC_mean  szan_PAC_max  szan_label  \n",
       "0            0.0           0.0           0  \n",
       "1            0.0           0.0           0  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pac_scores = pd.read_csv(PAC_SCORES_PATH)\n",
    "df_pac_scores.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polish Polyglot sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sentiment(text):\n",
    "    \n",
    "    # detect and delete invalid characters first\n",
    "    t = text\n",
    "    invalid = set()\n",
    "    for i, ch in enumerate(t):\n",
    "        try:\n",
    "            Text(f\"Char: {ch}\").words\n",
    "        except:\n",
    "            invalid.add(ch)\n",
    "    for ch in invalid:\n",
    "        t = t.replace(ch, '')\n",
    "    \n",
    "    t = Text(t)\n",
    "    sents = list([])\n",
    "    for w in t.words:\n",
    "        try:\n",
    "            s = w.polarity\n",
    "        except ValueError:\n",
    "            s = 0\n",
    "        sents.append(s)\n",
    "    sents = np.array(sents)\n",
    "    \n",
    "    return np.size(sents[sents==-1]), np.size(sents[sents==0]), np.size(sents[sents==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 17, 0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sentiment('Wróciły pisowskie trójki sądy doraźne koksowniki i SKOTy, do tego PiS gwałci żeby nie robić aborcji')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5, 0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sentiment('Faszystowskie sądy ach faszystowskie sądy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters, syllables, words counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'pl_PL' in pyphen.LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = pyphen.Pyphen(lang='pl_PL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_numbers(text):\n",
    "    num_chars = len(text.replace(' ', ''))\n",
    "    num_syllables = sum([len(dic.inserted(word).split('-')) for word in text.split(' ')])\n",
    "    num_words = len(text.split(' '))\n",
    "    num_unique_words = len(set(text.lower().split(' ')))\n",
    "    \n",
    "    return num_chars, num_syllables, num_words, num_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 33, 16, 16)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_numbers('Wróciły pisowskie trójki sądy doraźne koksowniki i SKOTy, do tego PiS gwałci żeby nie robić aborcji')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 13, 5, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_numbers('Faszystowskie sądy ach faszystowskie sądy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 34, 21, 20)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_numbers(lemmatize_text('Wróciły pisowskie trójki sądy doraźne koksowniki i SKOTy, do tego PiS gwałci żeby nie robić aborcji'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 11, 5, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_numbers(lemmatize_text('Faszystowskie sądy ach faszystowskie sądy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate above other scores for all tweets.**\n",
    "\n",
    "1. Load relevant data with sanitized tweets.\n",
    "2. For each tweet:\n",
    "    1. Remove invalid (for polyglot) characters which cause errors.\n",
    "    2. Determine how many words have which of three sentiment types.\n",
    "    3. Count characters, syllables, words and unique words.\n",
    "    2. Write all values into .csv row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTHER_SCORES_PATH = 'data/sady_main/sady_other_scores.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(OTHER_SCORES_PATH):\n",
    "    with open(OTHER_SCORES_PATH, 'w') as f:\n",
    "        csv.writer(f).writerow([\n",
    "            'id', 'tweet',\n",
    "            's_neg', 's_neu', 's_pos',\n",
    "            'n_chars', 'n_sylls', 'n_words', 'nu_words',\n",
    "            'nl_chars', 'nl_sylls', 'nl_words', 'nlu_words',\n",
    "        ])\n",
    "\n",
    "    for _id, tweet in tqdm(df_data.iterrows(), total=len(df_data)):\n",
    "        scores = dict({})\n",
    "        \n",
    "        scores['neg'], scores['neu'], scores['pos'] = text_sentiment(tweet['tweet'])\n",
    "        scores['chars'], scores['sylls'], scores['words'], scores['u_words'] = text_numbers(tweet['tweet'])\n",
    "        scores['l_chars'], scores['l_sylls'], scores['l_words'], scores['l_u_words'] = text_numbers(tweet['lemmatized'])\n",
    "        \n",
    "        with open(OTHER_SCORES_PATH, 'a') as f:\n",
    "            csv.writer(f).writerow([\n",
    "                _id, tweet['tweet'],\n",
    "                scores['neg'], scores['neu'], scores['pos'],\n",
    "                scores['chars'], scores['sylls'], scores['words'], scores['u_words'],\n",
    "                scores['l_chars'], scores['l_sylls'], scores['l_words'], scores['l_u_words'],\n",
    "            ])\n",
    "        del scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>s_neg</th>\n",
       "      <th>s_neu</th>\n",
       "      <th>s_pos</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_sylls</th>\n",
       "      <th>n_words</th>\n",
       "      <th>nu_words</th>\n",
       "      <th>nl_chars</th>\n",
       "      <th>nl_sylls</th>\n",
       "      <th>nl_words</th>\n",
       "      <th>nlu_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Polska Polityka: Sądy bardziej bezkarne niż w PRL</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "\n",
       "                                                                                                             tweet  \\\n",
       "0   Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych   \n",
       "1                                                               Polska Polityka: Sądy bardziej bezkarne niż w PRL    \n",
       "\n",
       "   s_neg  s_neu  s_pos  n_chars  n_sylls  n_words  nu_words  nl_chars  \\\n",
       "0      0     18      0       95       36       17        16        98   \n",
       "1      0      9      0       42       17        9         9        68   \n",
       "\n",
       "   nl_sylls  nl_words  nlu_words  \n",
       "0        35        20         19  \n",
       "1        28        15         14  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other_scores = pd.read_csv(OTHER_SCORES_PATH)\n",
    "df_other_scores.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hateful phrases topics detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find top 5 topic sentences for pharases of each hate type.**\n",
    "\n",
    "1. For each hate type:\n",
    "    1. Get relevant lemmatized and synonymic phrases and combine them into one list.\n",
    "    2. Fit CountVectorizer and LDA model.\n",
    "    3. Save trained model into pickle archive.\n",
    "    4. For each tweet:\n",
    "        1. Calculate PAC scores of each of 10 topics appearance.\n",
    "        2. Save into .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOPICS, N_WORDS = 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2713ebd3601f490cb981652820a64a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for hate_type, l_phrases, s_phrases in tqdm(zip(HATE_TYPES, lemmatized_phrases, synonymic_phrases), total=len(HATE_TYPES)):\n",
    "    \n",
    "    cv = CountVectorizer(stop_words=polish_stopwords)\n",
    "    count_data = cv.fit_transform(l_phrases + s_phrases)\n",
    "    \n",
    "    lda_model = LDA(n_components=N_TOPICS, n_jobs=-1)\n",
    "    lda_model.fit(count_data)\n",
    "    \n",
    "    with open(f'models/lda/lda_{hate_type}.pkl', 'wb') as f:\n",
    "        pickle.dump([lda_model, cv], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_topics(lda_model, lda_cv, n_words):\n",
    "    words = lda_cv.get_feature_names()\n",
    "    \n",
    "    topics = list([' '.join([words[i] for i in topic.argsort()[:-n_words - 1:-1]])\n",
    "                   for topic in lda_model.components_])\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_PAC_SCORES_PATH = 'data/sady_main/sady_topic_pac_scores.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663aaae60c404b93977157e93b9c7386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15202.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(TOPIC_PAC_SCORES_PATH):\n",
    "    with open(TOPIC_PAC_SCORES_PATH, 'w') as f:\n",
    "        csv.writer(f).writerow([\n",
    "            'id', 'tweet',\n",
    "            'wyz_min', 'wyz_mean', 'wyz_max',\n",
    "            'groz_min', 'groz_mean', 'groz_max',\n",
    "            'wyk_min', 'wyk_mean', 'wyk_max',\n",
    "            'odcz_min', 'odcz_mean', 'odcz_max', \n",
    "            'pon_min', 'pon_mean', 'pon_max',\n",
    "            'styg_min', 'styg_mean', 'styg_max',\n",
    "            'szan_min', 'szan_mean', 'szan_max',\n",
    "            'vulg_min', 'vulg_mean', 'vulg_max',\n",
    "        ])\n",
    "    \n",
    "    for _id, tweet in tqdm(df_data.iterrows(), total=len(df_data)):\n",
    "        scores = dict({})\n",
    "        \n",
    "        for hate_type in HATE_TYPES + ['vulg']:\n",
    "            with open(f'models/lda/lda_{hate_type}.pkl', 'rb') as f:\n",
    "                lda_model, cv = pickle.load(f)\n",
    "\n",
    "            topics = lda_topics(lda_model, cv, n_words=N_WORDS)\n",
    "            sc_min, sc_mean, sc_max = list([]), list([]), list([])\n",
    "\n",
    "            for topic in topics:\n",
    "                mn, mean, mx = calculate_PAC(tweet['lemmatized'], topic, lemmatized=True,\n",
    "                                             stopwords=polish_stopwords)\n",
    "                sc_min.append(mn)\n",
    "                sc_mean.append(mean)\n",
    "                sc_max.append(mx)\n",
    "            \n",
    "            scores[f'{hate_type}_min'] = np.min(sc_min)\n",
    "            scores[f'{hate_type}_mean'] = np.mean(sc_mean)\n",
    "            scores[f'{hate_type}_max'] = np.max(sc_max)\n",
    "            del sc_min, sc_mean, sc_max\n",
    "            \n",
    "        with open(TOPIC_PAC_SCORES_PATH, 'a') as f:\n",
    "            csv.writer(f).writerow([\n",
    "                _id, tweet['tweet'],\n",
    "                scores['wyz_min'], scores['wyz_mean'], scores['wyz_max'],\n",
    "                scores['groz_min'], scores['groz_mean'], scores['groz_max'],\n",
    "                scores['wyk_min'], scores['wyk_mean'], scores['wyk_max'],\n",
    "                scores['odcz_min'], scores['odcz_mean'], scores['odcz_max'],\n",
    "                scores['pon_min'], scores['pon_mean'], scores['pon_max'],\n",
    "                scores['styg_min'], scores['styg_mean'], scores['styg_max'],\n",
    "                scores['szan_min'], scores['szan_mean'], scores['szan_max'],\n",
    "                scores['vulg_min'], scores['vulg_mean'], scores['vulg_max'],\n",
    "            ])\n",
    "            \n",
    "        del scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>wyz_min</th>\n",
       "      <th>wyz_mean</th>\n",
       "      <th>wyz_max</th>\n",
       "      <th>groz_min</th>\n",
       "      <th>groz_mean</th>\n",
       "      <th>groz_max</th>\n",
       "      <th>wyk_min</th>\n",
       "      <th>wyk_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>pon_max</th>\n",
       "      <th>styg_min</th>\n",
       "      <th>styg_mean</th>\n",
       "      <th>styg_max</th>\n",
       "      <th>szan_min</th>\n",
       "      <th>szan_mean</th>\n",
       "      <th>szan_max</th>\n",
       "      <th>vulg_min</th>\n",
       "      <th>vulg_mean</th>\n",
       "      <th>vulg_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Polska Polityka: Sądy bardziej bezkarne niż w PRL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-0.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "\n",
       "                                                                                                             tweet  \\\n",
       "0   Dokładnie! Dlatego trzeba komuchów gonić przed sądy póki żyją. I mięć otwarte oczy na komuchów zakamuflowanych   \n",
       "1                                                               Polska Polityka: Sądy bardziej bezkarne niż w PRL    \n",
       "\n",
       "    wyz_min  wyz_mean   wyz_max  groz_min  groz_mean  groz_max  wyk_min  \\\n",
       "0 -0.111111  0.000000  0.111111  0.000000        0.0  0.000000      0.0   \n",
       "1  0.000000  0.011111  0.111111 -0.111111        0.0  0.111111      0.0   \n",
       "\n",
       "   wyk_mean  ...  pon_max  styg_min  styg_mean  styg_max  szan_min  szan_mean  \\\n",
       "0  0.000000  ...      0.0  0.000000   0.011111  0.111111       0.0        0.0   \n",
       "1  0.033333  ...      0.0 -0.111111  -0.022222  0.000000       0.0        0.0   \n",
       "\n",
       "   szan_max  vulg_min  vulg_mean  vulg_max  \n",
       "0       0.0       0.0        0.0       0.0  \n",
       "1       0.0       0.0        0.0       0.0  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_pac_scores = pd.read_csv(TOPIC_PAC_SCORES_PATH)\n",
    "df_topic_pac_scores.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
